{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document deduplication\n",
    "\n",
    "Perform a basic deduplication of documents using cosine similarity.\n",
    "\n",
    "\n",
    "Use **scipy=1.3.1** to avoid library load error `(Library not loaded: @rpath/libopenblas.dylib)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim import corpora\n",
    "from gensim.similarities import Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wb_nlp.cleaning.cleaner' from '/Users/avsolatorio/WBG/wb_nlp/src/wb_nlp/cleaning/cleaner.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wb_nlp.cleaning import cleaner\n",
    "from wb_nlp import dir_manager\n",
    "importlib.reload(cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = 'IMF'\n",
    "DATA_DIR = dir_manager.get_data_dir('raw', 'CORPUS', CORPUS, 'TXT_ORIG')\n",
    "EXTENSION = 'txt'\n",
    "ID_PATTERN = 'wb_\\d+' if CORPUS == 'WB' else 'imf_[a-z0-9]+' if CORPUS == 'IMF' else None\n",
    "PROCESS_PROB = 0.1\n",
    "SEED = 1029\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.97\n",
    "\n",
    "DUPLICATES_DIR = dir_manager.get_data_dir('preprocessed', 'duplicates')\n",
    "\n",
    "if not os.path.isdir(DUPLICATES_DIR):\n",
    "    os.makedirs(DUPLICATES_DIR)\n",
    "\n",
    "PHRASER_FILE = os.path.join(DUPLICATES_DIR, 'bigram_model.pickle')\n",
    "DUPLICATES_CORPUS_FILE = os.path.join(DUPLICATES_DIR, 'corpus_generator.pickle')\n",
    "SIMILARITY_OUTPUT_PREFIX = os.path.join(DUPLICATES_DIR, 'corpus_similarity.gensim')\n",
    "DUPLICATE_DOC_IDS_FILE = os.path.join(DUPLICATES_DIR, 'duplicate_doc_ids.dict.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cleaner = cleaner.SimpleCleaner()\n",
    "simple_corpus_generator = cleaner.CorpusCleaner(\n",
    "    DATA_DIR, cleaner=simple_cleaner.clean_text,\n",
    "    id_pattern=ID_PATTERN, extension=EXTENSION,\n",
    "    process_prob=PROCESS_PROB, seed=SEED)\n",
    "\n",
    "# lda_corpus_generator = cleaner.CorpusCleaner(DATA_DIR, lda_cleaner.clean_text, extension=EXTENSION)\n",
    "# lda_cleaner = cleaner.LDACleaner()\n",
    "\n",
    "# word2vec_corpus_generator = cleaner.CorpusCleaner(DATA_DIR, word2vec_cleaner.clean_text, extension=EXTENSION)\n",
    "# word2vec_cleaner = cleaner.Word2VecCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_generator = simple_corpus_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents and compute phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "try:\n",
    "    corpus_generator.reset()\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "if os.path.isfile(PHRASER_FILE):\n",
    "    bigram_phraser = Phraser.load(PHRASER_FILE)\n",
    "else:\n",
    "    bigram = Phrases(corpus_generator, min_count=1)\n",
    "    bigram_phraser = Phraser(bigram)\n",
    "    bigram_phraser.save(PHRASER_FILE)\n",
    "    del(bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the corpus generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_generator.save(DUPLICATES_CORPUS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the bigram docs, dictionary, and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dictionary = corpora.Dictionary(corpus_generator.stream_gensim_transformer(bigram_phraser))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the similarity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "index = Similarity(\n",
    "    corpus=corpus_generator.stream_gensim_transformer(bigram_phraser, dictionary),\n",
    "    num_features=len(dictionary),\n",
    "    output_prefix=SIMILARITY_OUTPUT_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17149858 0.17149858 0.17149858 0.17149858 0.34299716 0.17149858\n",
      " 0.17149858 0.17149858 0.17149858 0.17149858 0.17149858 0.17149858\n",
      " 0.34299716 0.17149858 0.17149858 0.17149858 0.17149858 0.17149858\n",
      " 0.17149858 0.17149858 0.17149858 0.17149858 0.17149858 0.17149858\n",
      " 0.17149858 0.17149858 0.17149858 0.17149858 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0.99999994 0.01642659]\n"
     ]
    }
   ],
   "source": [
    "print(index.vector_by_id(0))\n",
    "print(index.similarity_by_id(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect duplicate documents based on similarity threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "unique_doc_ids = set()\n",
    "duplicated_docs = []\n",
    "\n",
    "# for doc_id, doc in enumerate(corpus_generator.stream_gensim_transformer(bigram_phraser, dictionary)):\n",
    "for doc_id, sim in enumerate(index):\n",
    "    indices = np.where(sim > SIMILARITY_THRESHOLD)[0]\n",
    "\n",
    "    if len(indices) == 1:\n",
    "        unique_doc_ids.add(doc_id)\n",
    "    else:\n",
    "        duplicated_docs.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = dict(\n",
    "    unique_doc_ids=unique_doc_ids,\n",
    "    duplicated_docs=duplicated_docs)\n",
    "\n",
    "with open(DUPLICATE_DOC_IDS_FILE, 'wb') as fl:\n",
    "    pickle.dump(payload, fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the corpus generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_generator.save(DUPLICATES_CORPUS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved corpus generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_corpus_generator = cleaner.CorpusCleaner(DATA_DIR, simple_cleaner.clean_text, extension=EXTENSION)\n",
    "load_corpus_generator.load(DUPLICATES_CORPUS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load_corpus_generator.reset()\n",
    "# for i in load_corpus_generator:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb_nlp",
   "language": "python",
   "name": "wb_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
