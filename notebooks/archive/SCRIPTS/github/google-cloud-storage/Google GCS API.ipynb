{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the server to access GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the google-cloud-storage package\n",
    "\n",
    "```\n",
    "conda install -c conda-forge google-cloud-storage\n",
    "```\n",
    "\n",
    "Create a service account key for the server by following the instructions in https://cloud.google.com/docs/authentication/getting-started.\n",
    "\n",
    "In creating a service account key, the permission can be set to `Role > Project > Viewer` to give read access to all resources. **Make sure to keep the key safe at all times!**\n",
    "\n",
    "Save the key and add upload it to the server. Use it as specified in the instruction above or in python it can be done as:\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'PATH/TO/SERVICE_KEY.json'\n",
    "```\n",
    "\n",
    "A quickstart guide can then be found here: https://googleapis.dev/python/storage/latest/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './WB Analytics-74d8961073eb.json'\n",
    "\n",
    "bucket_name = 'wb-analytics'\n",
    "# prefix = 'ipython_notebooks_python_and_R_scripts_imports_full/'\n",
    "download_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcs_download_csv_json_gz(bucket_name, prefix, download_dir):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    target_dir = os.path.join(download_dir, prefix)\n",
    "\n",
    "    assert(os.path.isdir(download_dir))\n",
    "    assert(os.path.isdir(target_dir) == False)  # If the target directory exists, back it up first and delete the directory.\n",
    "\n",
    "    os.makedirs(target_dir)\n",
    "    \n",
    "    blobs = bucket.list_blobs(prefix=prefix)  # This includes the prefix\n",
    "\n",
    "    for ix, blob in enumerate(blobs):\n",
    "        print(blob.name)\n",
    "        if blob.name.endswith('.json.gz') or blob.name.endswith('.csv.gz'):\n",
    "            print(f'Saving {ix + 1}. {blob.name}...')\n",
    "            filename = blob.name[len(prefix):].replace('/', '__')\n",
    "            blob.download_to_filename(target_dir + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_usage_per_repository/\n",
      "module_usage_per_repository/module_usage_per_repository_20191120011240.csv.gz\n",
      "Saving 2. module_usage_per_repository/module_usage_per_repository_20191120011240.csv.gz...\n",
      "module_usage_per_repository/module_usage_per_repository_20191120233530.csv.gz\n",
      "Saving 3. module_usage_per_repository/module_usage_per_repository_20191120233530.csv.gz...\n"
     ]
    }
   ],
   "source": [
    "gcs_download_csv_json_gz(bucket_name=bucket_name, prefix='module_usage_per_repository/', download_dir=download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000000.json.gz...\n",
      "Saving 3. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000001.json.gz...\n",
      "Saving 4. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000002.json.gz...\n",
      "Saving 5. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000003.json.gz...\n",
      "Saving 6. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000004.json.gz...\n",
      "Saving 7. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000005.json.gz...\n",
      "Saving 8. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000006.json.gz...\n",
      "Saving 9. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000007.json.gz...\n",
      "Saving 10. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000008.json.gz...\n",
      "Saving 11. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000009.json.gz...\n",
      "Saving 12. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000010.json.gz...\n",
      "Saving 13. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000011.json.gz...\n",
      "Saving 14. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000012.json.gz...\n",
      "Saving 15. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000013.json.gz...\n",
      "Saving 16. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000014.json.gz...\n",
      "Saving 17. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000015.json.gz...\n",
      "Saving 18. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000016.json.gz...\n",
      "Saving 19. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000017.json.gz...\n",
      "Saving 20. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000018.json.gz...\n",
      "Saving 21. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000019.json.gz...\n",
      "Saving 22. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000020.json.gz...\n",
      "Saving 23. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000021.json.gz...\n",
      "Saving 24. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000022.json.gz...\n",
      "Saving 25. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000023.json.gz...\n",
      "Saving 26. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000024.json.gz...\n",
      "Saving 27. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000025.json.gz...\n",
      "Saving 28. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000026.json.gz...\n",
      "Saving 29. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000027.json.gz...\n",
      "Saving 30. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000028.json.gz...\n",
      "Saving 31. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000029.json.gz...\n",
      "Saving 32. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000030.json.gz...\n",
      "Saving 33. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000031.json.gz...\n",
      "Saving 34. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000032.json.gz...\n",
      "Saving 35. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000033.json.gz...\n",
      "Saving 36. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000034.json.gz...\n",
      "Saving 37. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000035.json.gz...\n",
      "Saving 38. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000036.json.gz...\n",
      "Saving 39. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000037.json.gz...\n",
      "Saving 40. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000038.json.gz...\n",
      "Saving 41. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000039.json.gz...\n",
      "Saving 42. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000040.json.gz...\n",
      "Saving 43. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000041.json.gz...\n",
      "Saving 44. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000042.json.gz...\n",
      "Saving 45. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000043.json.gz...\n",
      "Saving 46. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000044.json.gz...\n",
      "Saving 47. ipython_notebooks_python_and_R_scripts_imports_full/ipython_notebooks_python_and_R_scripts_imports_full-000000000045.json.gz...\n"
     ]
    }
   ],
   "source": [
    "gcs_download_csv_json_gz(bucket_name=bucket_name, prefix='ipython_notebooks_python_and_R_scripts_imports_full/', download_dir=download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stata_files_github/\n",
      "stata_files_github/stata_files_github_20191120233730.csv.gz\n",
      "Saving 2. stata_files_github/stata_files_github_20191120233730.csv.gz...\n"
     ]
    }
   ],
   "source": [
    "gcs_download_csv_json_gz(bucket_name=bucket_name, prefix='stata_files_github/', download_dir=download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "mongo = pymongo.MongoClient(port=27018)\n",
    "db = mongo['nlp']\n",
    "collection = db['github-bq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_id\": \"00tau/skyline-addon-easyqc\", \"description\": \"Add-on script for performing easy quality control tasks within Skyline\", \"fork_count\": 0, \"insertion_date\": \"2019-11-24T04:36:07.963844+00:00\", \"languages\": [{\"node\": {\"name\": \"R\"}}], \"last_updated_date\": \"2019-11-24T04:36:07.963844+00:00\", \"license_info\": \"GNU General Public License v3.0\", \"name\": \"skyline-addon-easyqc\", \"owner\": \"00tau\", \"primary_language\": \"R\", \"py_libs\": [], \"r_libs\": [\"chron\", \"ggplot2\", \"plyr\"], \"readme\": \"# Start using easyQC for statistical process and quality control in mass spectrometry workflows\\n\\n## Introduction\\n\\nThe program `easyQC` is an external tool for statistical process and quality\\ncontrol in mass spectrometry workflows that integrates nicely in the [Skyline\\nTargeted Proteomics\\nEnvironment](https://skyline.gs.washington.edu/labkey/project/home/software/Skyline/begin.view).\\n\\n## Feature list at a glance\\n\\n- Automatically sorts your data by date and time, and orders your observations\\n  with the most recent on the right.  (\\\"What? Does this mean I don't need to\\n  sort my data manually, as it is the case for some other software tools out\\n  there?\\\", \\\"Yes.\\\")\\n- Dynamically adapts to custom report templates. (See details below.)\\n- Flow charts for single peptides can optionally be grouped together by their\\n  common protein accession.   (See details below.)\\n- Plots are generated in a nice page layout, ready for printing.\\n- Observations are colour-coded by a beneficial four-colour-code.  This makes\\n  it particularly easy to detect deviations from the norm.\\n- Has a built in outlier detection, which provides you with useful robust\\n  features.  (See details below.)\\n- Plot as _many_ flow charts for as _many_ peptides as you like.\\n\\n## How to cite this software\\n\\nThe [Harvard UoB format]\\n(http://lrweb.beds.ac.uk/guides/a-guide-to-referencing/cite_computer_program)\\nsuggests to cite this software in the following fashion:\\n\\n    M\\u00f6bius, T.W. and Malchow, S. (2014) easyQC: Statistical Process and Quality\\n    Control in Mass Spectrometry Workflows (Version 1.0) [Computer program].\\n    Available at: http://00tau.github.io/skyline-addon-easyqc/ (Accessed 03.\\n    April, 2014)\\n\\nThank you for using (and citing) this software.\\n\\n## Installation using the skyline GUI\\n\\nSimply follow the GUI-clicking adventure by successively clicking on `Tools ->\\nExternal Tools -> External Tool Store`.  In the appearing list select (click\\non) `easyQC`.  You will be promoted for the path to `Rscript`, which needs to\\nbe installed on you system.\\n\\nWe have realised that since the introduction of \\\"Live Reports\\\" in new Versions\\nof Skyline, the import of new templates might fail.  If this is the case for\\nyou, make sure two switch off \\\"Live Reports\\\", restart Skyline, and try the\\ninstallation again.\\n\\nThe underlying code-base of `easyQC` relies on the R-packages\\n[ggplot2](http://ggplot2.org/), [plyr](http://plyr.had.co.nz/) and\\n[chron](http://cran.r-project.org/web/packages/chron/index.html).  Fortunately,\\nall these packages are hosted on [CRAN](http://cran.r-project.org/), and should\\nautomatically be installed into your R-environment, when installing `easyQC` in\\nSkyline.  If, for some reasons, this should not be the case for you, make sure\\nthese three packages are installed in your R-environment.\\n\\n## Description\\n\\nThe software comes with an exemplary report template called `easyQC`.  We\\nrecommend to just go with this template, but feel free to create your own.  The\\nabsolute necessary fields your template should contain are:\\n`PeptideModifiedSequence` and `PrecursorMz`.  These two fields are used as\\nidentifiers for your peptides, and, thus, all other fields should uniquely be\\nidentifiable by these two.  Optionally, the field `ProteinName` can be added to\\nyour template.\\n\\nBy default, the flow charts of ten peptides are grouped together into one plot\\neach.  If your report template also contains the associated protein accession\\nof each peptide, namely the field `ProteinName`, then all peptides which belong\\nto the same protein accession are grouped into one plot.\\n\\nBefore the calculation of the mean and standard deviations of each flow chart,\\nthe software will do some outlier detection of your data, namely [Grubbs' test\\nfor outliers](http://en.wikipedia.org/wiki/Grubbs%27_test_for_outliers) will be\\napplied.  Observations which are classified as outliers by this test are\\ndiscarded in the estimation of the mean and standard deviations.   This gives\\nthe estimated means and standard deviations some desirable\\n[robust](http://en.wikipedia.org/wiki/Robust_statistics) features.\\n\\n## You can also use easyQC as a stand-alone command line program\\n\\nOn Linux, you simply need to add the directory in which you have cloned\\n`easyQC`'s repository to your path.  Also make sure that `easyQC.r` is\\nexecutable.\\n\\n```\\n% git clone https://github.com/00tau/skyline-addon-easyqc.git\\n% cd skyline-addonn-easyqc\\n% chmod +x easyQC.r\\n% PATH=$(pwd):$PATH\\n```\\n\\nThe synopsis is as follows:\\n\\n```\\neasyQC.r [OPTIONS] REPORTFILE\\n```\\n\\nWhere `OPTIONS` is either `verbose` or noting.  For example, to produce some\\nquality control plots from a file `some-report-file.csv` that has been\\ngenerated by Skyline via some report template (e.g. the template `easyQC.skyr`\\nshould come in mind here), run either one of the following two code lines from\\nthe command line.\\n\\n```\\n% easyQC.r some-report-file.csv\\n% easyQC.r verbose some-report-file.csv\\n```\\n\\nThis will produce a file `some-report-file.pdf` with all the plots you need.\\n\\nYou what to install the most recent and latest version in Skyline\\n-----------------------------------------------------------------\\n\\nIf for some reasons, you are interested in installing the latest GitHub-version\\n(or any other version of this software that is available on GitHub), the\\nrepository contains a convenient Makefile that will create the necessary files\\nfor the installation process for you.  Simply type:\\n\\n```\\n% make\\n```\\n\\nThis will create a `easyQC.zip` file which contains the needed install scripts\\nfor Skyline.  Now, just follow your Skyline-GUI.\\n\\nAuthors\\n-------\\n\\nThomas W. D. M\\u00f6bius (Maintainer, R-programming), Sebastian Malchow (Skyline wizard)\\n\", \"repo_created_at\": \"2014-02-25T15:26:30Z\", \"repo_id\": \"MDEwOlJlcG9zaXRvcnkxNzE3NzYxOQ==\", \"repo_updated_at\": \"2014-04-04T14:56:54Z\", \"stargazers\": 0, \"topics\": [], \"watchers\": 1}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(collection.find_one({'languages': {'$exists': True}})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498610"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529976"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.create_index([('readme', pymongo.TEXT)], name='readme_text_idx')\n",
    "collection.create_index([('description', pymongo.TEXT)], name='description_text_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.find_one({'primary_language': 'R', 'readme': {'$text': {'$search': 'poverty'}}})\n",
    "collection.find({'$text': {'$search': \"\\\"climate change\\\"\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}