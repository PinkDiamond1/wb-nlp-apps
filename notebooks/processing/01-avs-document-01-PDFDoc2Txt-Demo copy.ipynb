{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "\n",
    "import spacy\n",
    "import tika\n",
    "from tika import parser\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={'figure.figsize': (16, 9.)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wb_nlp.processing import document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hints\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains examples of how the `PDFDoc2Txt` class can be used to convert pdf documents into formatted text. Additional methods implemented in this class can also be applied to raw texts extracted from PDFs.\n",
    "\n",
    "We start by creating an instance of the `PDFDoc2Txt`—`pdf_parser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_parser = document.PDFDoc2Txt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing a pdf file\n",
    "\n",
    "Parsing a pdf file starts with the `parse` method. This method accepts a buffer of byte object or a string to a url or file path. The source type must be specified for the parser to correctly execute the processing.\n",
    "\n",
    "Below is the implementation of the `parse` method. Tika is the main driver of the parser. We use the `xmlContent` flag to specify that we want to get an xml formatted output. The xml output contains relevant structure that we can leverage to generate an informed reconstruction of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mSignature:\u001b[0m \u001b[0mpdf_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'buffer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mSource:\u001b[0m   \n    \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'buffer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Parse a PDF document to text from different source types.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        Args:\u001b[0m\n\u001b[0;34m            source:\u001b[0m\n\u001b[0;34m                Source of the PDF that needs to be converted.\u001b[0m\n\u001b[0;34m                The source could be a url, a path, or a buffer/file-like object\u001b[0m\n\u001b[0;34m                to the PDF file.\u001b[0m\n\u001b[0;34m            source_type:\u001b[0m\n\u001b[0;34m                Specification of which source type is being provided in `source`.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        Returns:\u001b[0m\n\u001b[0;34m            A string containing the parsed pdf file.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0msource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mpdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmlContent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0msource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mpdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmlContent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0msource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'buffer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mpdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmlContent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Unknown source_type: `{source_type}`'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'page'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mtext_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mtext_pages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDFDoc2Txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtext_pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mFile:\u001b[0m      ~/WBG/wb_nlp/src/wb_nlp/processing/document.py\n\u001b[0;31mType:\u001b[0m      method\n"
    }
   ],
   "source": [
    "??pdf_parser.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing a single page\n",
    "\n",
    "The xml returned by Tika contains page information captured by div tags. We used this to process documents by page.\n",
    "\n",
    "The `process_page` method takes a tag element corresponding to the extracted page. Page level processing is then applied such as consolidation of paragraphs in the page and fixing footnote citations. We also perform concatenation of likely fragmented paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mSignature:\u001b[0m \u001b[0mpdf_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m <no docstring>\n\u001b[0;31mSource:\u001b[0m   \n    \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mprocess_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mparagraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFDoc2Txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate_paragraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFDoc2Txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_footnote_citations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mprev_paragraph_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparagraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparagraphs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparagraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mprev_paragraph_end\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[a-zA-Z\\-\\,]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_paragraph_end\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# .isalpha():\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparagraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0mparagraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0mparagraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;31m# for p in paragraphs:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;31m#     doc = self.nlp(p)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;31m#     self.sentences.extend(list(doc.sents))\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mparagraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mparagraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mFile:\u001b[0m      ~/WBG/wb_nlp/src/wb_nlp/processing/document.py\n\u001b[0;31mType:\u001b[0m      function\n"
    }
   ],
   "source": [
    "??pdf_parser.process_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paragraph consolidation algorithm\n",
    "\n",
    "The following method `consolidate_paragraph` contains the different heuristics for identifying fragmentation of paragraphs/sentences extracted from the pdf file.\n",
    "\n",
    "This method is a static method allowing us to use this on arbitrary text document that may contain sentence level fragmentation due to OCR or other X-to-text conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mSignature:\u001b[0m\n\u001b[0mpdf_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate_paragraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mtext_paragraph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmin_fragment_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mSource:\u001b[0m   \n    \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mconsolidate_paragraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_paragraph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_fragment_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Consolidate a `text_paragraph` with possible multiple newlines into one logical paragraph.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        Tika provides access to extracted text by paragraph. These paragraphs, however, may contain\u001b[0m\n\u001b[0;34m        multiple newlines that break the paragraph arbitrarily. This function implements some heuristics\u001b[0m\n\u001b[0;34m        to recover a logical representation of the paragraph.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        Args:\u001b[0m\n\u001b[0;34m            text_paragraph:\u001b[0m\n\u001b[0;34m                Text corresponding to an extracted paragraph from Tika.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        Returns:\u001b[0m\n\u001b[0;34m            A string corresponding to a logical paragraph.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mreplace_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'’'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'“'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'”'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'\"'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mline_seps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mline_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mtext_paragraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_paragraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(.+)(?:$|\\r?\\n)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_paragraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mprev_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mprev_line_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprev_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mlen_prev_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_line\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mlen_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'•'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mlen_prev_line\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin_fragment_len\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen_line\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_fragment_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0;31m# We consider joining consecutive lines if the previous line is\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0;31m# reasonably long enough to be considered a valid fragment.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mprev_line_end\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline_seps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprev_line_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                    \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_line\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                    \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_line\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^\\.\\:\\?]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_line_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_line\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreplace_chars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mFile:\u001b[0m      ~/WBG/wb_nlp/src/wb_nlp/processing/document.py\n\u001b[0;31mType:\u001b[0m      function\n"
    }
   ],
   "source": [
    "??pdf_parser.consolidate_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "### Run tika docker image first.\n",
    "\n",
    "https://hub.docker.com/r/apache/tika\n",
    "\n",
    "```\n",
    "sudo docker pull apache/tika\n",
    "sudo docker run -d -p 9998:9998 apache/tika\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WB Docs repository contains pdf and txt versions of documents. However, some text versions are not formatted properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://documents1.worldbank.org/curated/en/735931527600661308/text/126663-WP-PUBLIC-P164538-Malawi-Economic-Monitor-7-Realizing-Safety-Nets-Potential.txt'\n",
    "txt_original = requests.get(url).content.decode('utf-8')\n",
    "\n",
    "# pdf_url = 'http://documents1.worldbank.org/curated/en/735931527600661308/pdf/126663-WP-PUBLIC-P164538-Malawi-Economic-Monitor-7-Realizing-Safety-Nets-Potential.pdf'\n",
    "\n",
    "pdf_url = 'https://openknowledge.worldbank.org/bitstream/handle/10986/34013/Designing-a-Credit-Facility-for-Women-Entrepreneurs-Lessons-from-the-Ethiopia-Women-Entrepreneurship-Development-Project.pdf?sequence=4&isAllowed=y'\n",
    "txt_parsed = pdf_parser.parse(source=pdf_url, source_type='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = requests.get(pdf_url).content\n",
    "xml = document.parser.from_buffer(buffer, xmlContent=True)['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlB = document.BeautifulSoup(xml, features='html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning process:\n",
    "\n",
    "- If coming from pdf, parse with tika to convert into xml using xmlContent=True.\n",
    "- Process text per page. If page contains very few or no sentences, we could drop it since it may be a page full of tables or other details.\n",
    "- Expand acronyms.\n",
    "- Check length of text.\n",
    "- Lemmatize.\n",
    "- Remove noise.\n",
    "- Detect language.\n",
    "- Spell check.\n",
    "- Respeller.\n",
    "- Plural-singular map?\n",
    "- Create recognizers of entities, e.g., countries, names, places, etc.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/api/annotation\n",
    "POS_TAGS = ['POS', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'SPACE']\n",
    "\n",
    "LDA_POS_TAGS = [\n",
    "    'ADJ', 'NOUN', 'PROPN', 'VERB'\n",
    "]\n",
    "\n",
    "EMBEDDING_POS_TAGS = [\n",
    "    'ADJ', 'NOUN'\n",
    "]\n",
    "\n",
    "\n",
    "INVALID_ENT_TYPE = [\n",
    "    'DATE', 'MONEY', 'CARDINAL', 'PERCENT',\n",
    "]\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # text = xmlB.find_all('div', attrs={'class': 'page'})[page_num].text\n",
    "    text = (\n",
    "        text\n",
    "        .replace('\\n', ' ')\n",
    "        .replace('’', \"'\")\n",
    "        .replace('“', '\"')\n",
    "        .replace('”', '\"')\n",
    "    )\n",
    "\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for t in doc:\n",
    "        if t.ent_type_:\n",
    "            print((t.text, t.lemma_, t.pos_, t.ent_type_, t.ent_iob_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('Le', 'Le', 'PROPN', 'FAC', 'B')\n('s', 's', 'PROPN', 'FAC', 'I')\n('s', 's', 'NOUN', 'FAC', 'I')\n('WEDP', 'WEDP', 'PROPN', 'FAC', 'B')\n('January', 'January', 'PROPN', 'DATE', 'B')\n('2014', '2014', 'NUM', 'DATE', 'I')\n('12', '12', 'NUM', 'CARDINAL', 'B')\n('6', '6', 'NUM', 'CARDINAL', 'B')\n('the', 'the', 'DET', 'DATE', 'B')\n('end', 'end', 'NOUN', 'DATE', 'I')\n('of', 'of', 'ADP', 'DATE', 'I')\n('the', 'the', 'DET', 'DATE', 'I')\n('calendar', 'calendar', 'NOUN', 'DATE', 'I')\n('year', 'year', 'NOUN', 'DATE', 'I')\n('ETB', 'ETB', 'PROPN', 'MONEY', 'B')\n('456.6', '456.6', 'NUM', 'MONEY', 'I')\n('million', 'million', 'NUM', 'MONEY', 'I')\n('USD', 'USD', 'PROPN', 'MONEY', 'B')\n('23.3', '23.3', 'NUM', 'MONEY', 'I')\n('million', 'million', 'NUM', 'MONEY', 'I')\n('1,863', '1,863', 'NUM', 'CARDINAL', 'B')\n('over', 'over', 'ADP', 'CARDINAL', 'B')\n('half', 'half', 'DET', 'CARDINAL', 'I')\n('WEDP', 'WEDP', 'PROPN', 'ORG', 'B')\n('Ethiopia', 'Ethiopia', 'PROPN', 'GPE', 'B')\n('66', '66', 'NUM', 'PERCENT', 'B')\n('percent', 'percent', 'NOUN', 'PERCENT', 'I')\n('first', 'first', 'ADJ', 'ORDINAL', 'B')\n('99.1', '99.1', 'NUM', 'PERCENT', 'B')\n('percent', 'percent', 'NOUN', 'PERCENT', 'I')\n('3,083', '3,083', 'NUM', 'CARDINAL', 'B')\n('mid-2015', 'mid-2015', 'ADJ', 'DATE', 'B')\n('WEDP', 'WEDP', 'PROPN', 'ORG', 'B')\n('WEDP', 'WEDP', 'PROPN', 'ORG', 'B')\n('the', 'the', 'DET', 'DATE', 'B')\n('end', 'end', 'NOUN', 'DATE', 'I')\n('of', 'of', 'ADP', 'DATE', 'I')\n('2017', '2017', 'NUM', 'DATE', 'I')\n('Italy', 'Italy', 'PROPN', 'GPE', 'B')\n('USD', 'usd', 'SYM', 'MONEY', 'B')\n('15.8', '15.8', 'NUM', 'MONEY', 'I')\n('million', 'million', 'NUM', 'MONEY', 'I')\n('Japan', 'Japan', 'PROPN', 'GPE', 'B')\n('USD', 'usd', 'SYM', 'MONEY', 'B')\n('50', '50', 'NUM', 'MONEY', 'I')\n('million', 'million', 'NUM', 'MONEY', 'I')\n('WEDP', 'WEDP', 'PROPN', 'ORG', 'B')\n('second', 'second', 'ADJ', 'ORDINAL', 'B')\n('4', '4', 'NUM', 'CARDINAL', 'B')\n('the', 'the', 'DET', 'ORG', 'B')\n('European', 'European', 'PROPN', 'ORG', 'I')\n('Investment', 'Investment', 'PROPN', 'ORG', 'I')\n('Bank', 'Bank', 'PROPN', 'ORG', 'I')\n('34', '34', 'NUM', 'CARDINAL', 'B')\n('million', 'million', 'NUM', 'CARDINAL', 'I')\n('WEDP', 'WEDP', 'PROPN', 'ORG', 'B')\n('USD', 'USD', 'PROPN', 'MONEY', 'B')\n('145.7', '145.7', 'NUM', 'MONEY', 'I')\n('million', 'million', 'NUM', 'MONEY', 'I')\n('January', 'January', 'PROPN', 'DATE', 'B')\n('2014', '2014', 'NUM', 'DATE', 'I')\n('-', '-', 'PUNCT', 'DATE', 'I')\n('20', '20', 'NUM', 'CARDINAL', 'B')\n('14', '14', 'NUM', 'CARDINAL', 'B')\n('12', '12', 'NUM', 'CARDINAL', 'B')\n('10', '10', 'NUM', 'CARDINAL', 'B')\n('2', '2', 'NUM', 'CARDINAL', 'B')\n('2014', '2014', 'NUM', 'DATE', 'B')\n('2015', '2015', 'NUM', 'DATE', 'I')\n('3.96B', '3.96b', 'NUM', 'ORG', 'B')\n('8', '8', 'NUM', 'CARDINAL', 'B')\n('Addis', 'Addis', 'PROPN', 'GPE', 'B')\n('Ababa', 'Ababa', 'PROPN', 'GPE', 'I')\n('Adama', 'Adama', 'PROPN', 'GPE', 'B')\n('Bahir', 'Bahir', 'PROPN', 'PERSON', 'B')\n('Dar', 'Dar', 'PROPN', 'PERSON', 'I')\n('Dire', 'dire', 'VERB', 'PERSON', 'B')\n('Dawa', 'Dawa', 'PROPN', 'PERSON', 'I')\n('Hawassa', 'Hawassa', 'PROPN', 'PERSON', 'B')\n('Mekelle', 'Mekelle', 'PROPN', 'PERSON', 'B')\n('2', '2', 'NUM', 'DATE', 'B')\n('2014', '2014', 'NUM', 'DATE', 'I')\n('1', '1', 'NUM', 'CARDINAL', 'B')\n('19.6175', '19.6175', 'NUM', 'CARDINAL', 'B')\n('3', '3', 'NUM', 'MONEY', 'B')\n('Triodos', 'Triodos', 'PROPN', 'MONEY', 'I')\n('Facet', 'Facet', 'PROPN', 'MONEY', 'I')\n('2011', '2011', 'NUM', 'DATE', 'B')\n('Ethiopian', 'ethiopian', 'ADJ', 'NORP', 'B')\n('4', '4', 'NUM', 'PERSON', 'B')\n('Assela', 'Assela', 'PROPN', 'PERSON', 'I')\n('Axum', 'Axum', 'PROPN', 'GPE', 'B')\n('Dilla', 'Dilla', 'PROPN', 'GPE', 'B')\n('Gondar', 'Gondar', 'PROPN', 'PERSON', 'B')\n"
    }
   ],
   "source": [
    "clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2.3.2'"
     },
     "metadata": {},
     "execution_count": 304
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n        37, 38, 39, 40, 41, 42, 43, 44, 45]),)"
     },
     "metadata": {},
     "execution_count": 299
    }
   ],
   "source": [
    "page_num = 3\n",
    "text = re.sub('\\s+', ' ', xmlB.find_all('div', attrs={'class': 'page'})[page_num].text.replace('\\n', ' ').replace('’', \"'\").replace('“', '\"').replace('”', '\"')).strip()\n",
    "doc1 = nlp(text)\n",
    "\n",
    "docs1 = [s for s in doc1.sents]\n",
    "\n",
    "# for s in docs1:\n",
    "#     print(s)\n",
    "#     print('------')\n",
    "\n",
    "doc2 = nlp(re.sub('\\s+', ' ', txt_parsed[page_num].replace('\\n', ' ')))\n",
    "\n",
    "docs2 = [s for s in doc2.sents]\n",
    "\n",
    "# for s in docs2:\n",
    "#     print(s)\n",
    "#     print('------')\n",
    "\n",
    "len(docs1) == len(docs2)\n",
    "\n",
    "np.where(np.array([d1.text.strip() == d2.text.strip() for d1, d2 in zip(docs1, docs2)]) != True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(At the end of 2017, after securing external financing from Italy (USD 15.8 million) and Japan (USD 50 million), WEDP entered its second phase, expanding into 4 additional cities,4 adopting new technologies and innovations, and consolidating its interventions.,\n _3 Shortly thereafter, a WEDP revolving fund was approved to replenish the line of credit from repaid principals.)"
     },
     "metadata": {},
     "execution_count": 288
    }
   ],
   "source": [
    "ix = 29\n",
    "docs1[ix - 1], docs2[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for e, s in enumerate(doc2.sents):\n",
    "    # print(s)\n",
    "    # print('------')\n",
    "    if e == ix:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "_3 Shortly thereafter, a WEDP revolving fund was approved to replenish the line of credit from repaid principals."
     },
     "metadata": {},
     "execution_count": 290
    }
   ],
   "source": [
    "t = s[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 1.37 s, sys: 53.8 ms, total: 1.43 s\nWall time: 1.57 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pkg_resources\n",
    "from symspellpy.symspellpy import SymSpell\n",
    "\n",
    "# Set max_dictionary_edit_distance to avoid spelling correction\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=0, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "# term_index is the column of the term and count_index is the\n",
    "# column of the term frequency\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "# a sentence without any spaces\n",
    "# input_term = \"thequickbrownfoxjumpsoverthelazydog\"\n",
    "input_term = re.sub('\\s+', '', text)\n",
    "result = sym_spell.word_segmentation(input_term)\n",
    "# print(\"{}, {}, {}\".format(result.corrected_string, result.distance_sum,\n",
    "#                           result.log_prob_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "De signing aCr edit Facility for Wo men Ent rep rene ursLes sons from the EthiopiaWo men Ent rep rene ur ship D eve lop men tProject(WEDP)4WEDP loans began disbursing in J anu ary2014 through 12 partner micro finance institutions (MFIs) across 6 targeted cities in Ethi-opia.1By the end of the calendar year , the project had issued ETB456.6 million (USD23.3 million )to1,863 women entrepreneurs – over half the dedicated line of credit .2WEDP clients represented abroad spectrum of Ethiopia's business community , ranging from retail stores to restaurants to beauty salons .A mong those who borrowed ,66 percent were first - time borrowers , and yet repayment rates were healthy , standing at 99.1 percent .In tandem ,3,083 women had participated in entrepreneurship trainings .By mid -2015, the high demand for credit had led to a rapid depletion of WEDP funds , prompting the project leadership to explore additional sources of financing .In light of the declining balance , partner MFIs began disbursing from their internal funds .T his was an unexpected positive development , given MFIs' liquidity challenges .3S hort ly thereafter ,aWEDP revolving fund was approved to replenish the line of credit from repaid principals .At the end of 2017, after securing external financing from Italy(USD15.8 million ) and Japan(USD50 million ),WEDP entered its second phase , expanding into 4 additional cities ,4 adopting new technologies and innovations , and consolidating its interventions .Add it ion al funds from the Eu rope an In vestment Bank(EIB,USD34 million ) allowed WEDP to further refine and scale its efforts .In total , the externally funded line of credit reached USD145.7 million , while loans also continued to be disbursed from the revolving fund and MFIs' internal funds .TotalCumu lati veD is burse men tan dC lien tsJ anu ary2014-Dec ember 2019YEARCUMULATIVEWEDPLOANCL IENTSCUMULATIVETOTALDISBURSE MENT(ETB)20K18K16K14K12K10K8 K6K4K2K0K4.0B3.5B3.0B2.5B2.0 B1.5B1.0B0.5B0.0B20142015201 62017201820193.96B13,8701Add is A baba ,Adama,BahirDar,DireDawa,Ha was sa, and Mek ell e.22014 average exchange rate of USD1=ETB19.6175.3T rio dos F ace t(2011).EthiopianWo men Ent rep rene ur ship Capa city Buil ding Stu dies .4Assela,Axum,D ill a, and Gondar.\n"
    }
   ],
   "source": [
    "print(result.corrected_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('repaid', 'repay', 'VERB', '', 'O'),\n ('principal', 'principal', 'NOUN', '', 'O'),\n ('is', 'be', 'AUX', '', 'O'),\n ('beng', 'beng', 'NOUN', 'PERSON', 'B'),\n ('given', 'give', 'VERB', '', 'O'),\n ('to', 'to', 'ADP', '', 'O'),\n ('the', 'the', 'DET', '', 'O'),\n ('authority', 'authority', 'NOUN', '', 'O')]"
     },
     "metadata": {},
     "execution_count": 280
    }
   ],
   "source": [
    "s = nlp('repaid principal is beng given to the authority')\n",
    "print(s._.performed_spellCheck) \n",
    "[(t.text, t.lemma_, t.pos_, t.ent_type_, t.ent_iob_) for t in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result from direct txt version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MALAWI ECONOMIC MONITOR MAY 2018\n\fOVERVIEW\n                                                          challenges related to erratic energy and water\nThe Malawi Economic Monitor (MEM) provides an\n                                                          supply, which had a particularly negative impact\nanalysis of economic and structural development\n                                                          on      manufacturing.    Within  services,    the\nissues in Malawi. This edition was published in May\n                                                          performance of the wholesale and retail trade and\n2018. It follows on from the six previous editions of\n                                                          distribution sub-sectors declined as a result of\nthe MEM and is part of an ongoing series, with\n                                                          subdued domestic demand.\nfuture editions to follow twice per year.\n                                                          The prevalence of low-productivity rain-fed\nThe aim of the publication is to foster better-\n                                                          agriculture constrains poverty reduction. With most\ninformed policy analysis and debate regarding the\n                                                          of the population engaged in subsistence rain-fed\nkey challenges that Malawi faces in its endeavor to\n                                                          agriculture in rural areas, macroeconomic\nachieve high rates of stable, inclusive and\n                                                          instability and the sub-optimal performance of the\nsustainable economic growth.\n                                                          agricultural sector have contributed to the slow\nThe MEM consists of two parts: Part 1 presents a          pace of poverty reduction. Current estimates using\nreview of recent economic developments and a              the international poverty line (US$1.90 per day)\nmacroeconomic outlook. Part 2 focuses on a                indicate that 69.4 percent of the population is\nspecial selected topic relevant to Malawi’s               classified as being poor in 2017.\ndevelopment prospects.\n                                                          With the fiscal deficit at around six percent of GDP\nIn this edition, the special topic focuses on Social      over the past several years, in FY 2016/17 it\nSafety Nets. This is a defining moment for Malawi to      declined to 4.8 percent. This was mainly due to\ntransform its safety net. The recently approved           strong revenue collection performance and\nsecond Malawi National Social Support Program             controlled spending. The FY2017/18 budget\n(MNSSP II) works towards the creation of a dynamic        envisioned an even stronger performance by\nsafety net system that is positioned to better            lowering the deficit to 4 percent of GDP. The\nrespond to persistent poverty, recurrent shocks and       Government called for prudence in public\na demographic dividend. There is now robust               expenditure, with a commitment to avoiding the\nevidence showing how social safety nets can be            recurrent slippages that have characterized fiscal\nan efficient way to break the cycle of poverty and        performance in the past, and to continuing efforts\nvulnerability in Malawi.         Despite the evidence,    to intensify revenue collection.\ncurrent expenditure trends are low in terms of\nneeds and regional comparators. Strengthening             Despite the promising budget presentation, at mid-\nthe efficiency of safety nets is possible by reforming    year, the deficit significantly deteriorated. This was\nthe mix of program interventions and the links            due principally to three factors: a fall in revenue\nbetween them. While the social safety net sector in       due to weaker economic activity; a one-off\nMalawi has all the components necessary to                securitization of payment arrears dating back to\nfacilitate transformative change, this will require       FY2012/13 (1.2 percent of GDP); and an increase in\ncritical shifts in policy, institutional and investment   expenditure associated with the Agricultural\npriorities.                                               Development        and     Marketing      Corporation\n                                                          (ADMARC) financing (about 1 percent of GDP).\nECONOMIC DEVELOPMENTS\n                                                          Inflationary pressure subdued in the latter half of\nThe key messages of this edition of the MEM are\n                                                          2017, with the year-on-year headline rate falling to\nabout economic recovery and cautious optimism.\n                                                          7.1 percent in December. The decline was largely\nMalawi’s GDP growth picked up in 2017, but is\n                                                          due to a fall in food inflation, from a high of 20\nexpected to moderate in 2018, tracking agricultural\n                                                          percent in December 2016 to 4.3 percent in\nproduction. The Government is striving to achieve\n                                                          December 2017. An interesting reversal in the\nbudgetary prudence, although it continues to face\n                                                          factors driving inflation was noted in this period,\nchallenges in revenue collection. In the context of\n                                                          with non-food inflation remaining sticky and slowing\nsubdued inflation, the Government is continuing to\n                                                          only marginally, from a peak of 15.4 percent in\ncautiously ease monetary policy.\n                                                          December 2016 to 10 percent a year later. In 2017,\nAfter two years of depressed economic activity, the       the decline in food inflation was due to the bumper\nreal GDP growth picked up to 4 percent in 2017.           harvest during the 2016/17 growing season,\nWith a rebound in agricultural production, the            together with the maize export ban and carryover\nprospects for growth were generally positive.             stock from the humanitarian food purchases. These\nHowever, performance in the industrial and services       factors led to an abundant food supply and\nsectors was much weaker than anticipated.                 subdued prices.\nIndustry was adversely impacted by structural\n\n1 « MALAWI ECONOMIC MONITOR MAY 2018\n\fIn the context of the significant decline in headline         This could be further improved through efforts\ninflation, the RBM has continued to ease monetary             to broaden the tax base and to strengthen\npolicy. Since November 2016, t\n"
    }
   ],
   "source": [
    "print(txt_original[12850:20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Result from PDFDoc2Txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 « MALAWI ECONOMIC MONITOR MAY 2018\n\nOVERVIEW The Malawi Economic Monitor (MEM) provides an analysis of economic and structural development issues in Malawi. This edition was published in May 2018. It follows on from the six previous editions of the MEM and is part of an ongoing series, with future editions to follow twice per year.\n\nThe aim of the publication is to foster better- informed policy analysis and debate regarding the key challenges that Malawi faces in its endeavor to achieve high rates of stable, inclusive and sustainable economic growth.\n\nThe MEM consists of two parts: Part 1 presents a review of recent economic developments and a macroeconomic outlook. Part 2 focuses on a special selected topic relevant to Malawi's development prospects.\n\nIn this edition, the special topic focuses on Social Safety Nets. This is a defining moment for Malawi to transform its safety net. The recently approved second Malawi National Social Support Program (MNSSP II) works towards the creation of a dynamic safety net system that is positioned to better respond to persistent poverty, recurrent shocks and a demographic dividend.  There is now robust evidence showing how social safety nets can be an efficient way to break the cycle of poverty and vulnerability in Malawi.  Despite the evidence, current expenditure trends are low in terms of needs and regional comparators.  Strengthening the efficiency of safety nets is possible by reforming the mix of program interventions and the links between them.  While the social safety net sector in Malawi has all the components necessary to facilitate transformative change, this will require critical shifts in policy, institutional and investment priorities.\n\nECONOMIC DEVELOPMENTS The key messages of this edition of the MEM are about economic recovery and cautious optimism.\n\nMalawi's GDP growth picked up in 2017, but is expected to moderate in 2018, tracking agricultural production. The Government is striving to achieve budgetary prudence, although it continues to face challenges in revenue collection. In the context of subdued inflation, the Government is continuing to cautiously ease monetary policy.\n\nAfter two years of depressed economic activity, the real GDP growth picked up to 4 percent in 2017.\n\nWith a rebound in agricultural production, the prospects for growth were generally positive.\n\nHowever, performance in the industrial and services sectors was much weaker than anticipated.\n\nIndustry was adversely impacted by structural challenges related to erratic energy and water supply, which had a particularly negative impact on manufacturing. Within services, the performance of the wholesale and retail trade and distribution sub-sectors declined as a result of subdued domestic demand.\n\nThe prevalence of low-productivity rain-fed agriculture constrains poverty reduction. With most of the population engaged in subsistence rain-fed agriculture in rural areas, macroeconomic instability and the sub-optimal performance of the agricultural sector have contributed to the slow pace of poverty reduction. Current estimates using the international poverty line (US$1.90 per day) indicate that 69.4 percent of the population is classified as being poor in 2017.\n\nWith the fiscal deficit at around six percent of GDP over the past several years, in FY 2016/17 it declined to 4.8 percent. This was mainly due to strong revenue collection performance and controlled spending. The FY2017/18 budget envisioned an even stronger performance by lowering the deficit to 4 percent of GDP. The Government called for prudence in public expenditure, with a commitment to avoiding the recurrent slippages that have characterized fiscal performance in the past, and to continuing efforts to intensify revenue collection.\n\nDespite the promising budget presentation, at mid- year, the deficit significantly deteriorated. This was due principally to three factors: a fall in revenue due to weaker economic activity; a one-off securitization of payment arrears dating back to FY2012/13 (1.2 percent of GDP); and an increase in expenditure associated with the Agricultural Development and Marketing Corporation (ADMARC) financing (about 1 percent of GDP).\n\nInflationary pressure subdued in the latter half of 2017, with the year-on-year headline rate falling to 7.1 percent in December. The decline was largely due to a fall in food inflation, from a high of 20 percent in December 2016 to 4.3 percent in December 2017. An interesting reversal in the factors driving inflation was noted in this period, with non-food inflation remaining sticky and slowing only marginally, from a peak of 15.4 percent in December 2016 to 10 percent a year later. In 2017, the decline in food inflation was due to the bumper harvest during the 2016/17 growing season, together with the maize export ban and carryover stock from the humanitarian food purchases. These factors led to an abundant food supply and subdued prices.\n"
    }
   ],
   "source": [
    "print(txt[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "Using the text version from the WB Docs repository shows a fragmented structure. Columnar flows in a pdf page are literally placed side-by-side. This proves to be a challenge since inferring of sentences is not straighforward as simply replacing line breaks with spaces.\n",
    "\n",
    "On the other hand, we can see that the `PDFDoc2Txt` has managed to recover the logical sentences in the text. It was able to properly concatenate fragmented sentences and also identified which correspond to a single column flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb_nlp",
   "language": "python",
   "name": "wb_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}