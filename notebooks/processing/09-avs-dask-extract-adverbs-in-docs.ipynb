{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "wb_nlp",
   "display_name": "wb_nlp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import get_worker\n",
    "from dask.distributed import Client, LocalCluster, progress\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Client: 'tcp://127.0.0.1:33611' processes=4 threads=4, memory=24.00 GB>",
      "text/html": "<table style=\"border: 2px solid white;\">\n<tr>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Client</h3>\n<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n  <li><b>Scheduler: </b>tcp://127.0.0.1:33611</li>\n  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n</ul>\n</td>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Cluster</h3>\n<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n  <li><b>Workers: </b>4</li>\n  <li><b>Cores: </b>4</li>\n  <li><b>Memory: </b>24.00 GB</li>\n</ul>\n</td>\n</tr>\n</table>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# client = Client(processes=True)\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=1, memory_limit='6GB', processes=True)\n",
    "client = Client(cluster)\n",
    "# client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()\n",
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "from wb_nlp import dir_manager\n",
    "from wb_nlp.cleaning import cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(107, '/workspace/data/preprocessed/sample_data/TXT_SAMPLE/wb_13720575.txt')"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "SOURCE_DIR = dir_manager.get_data_dir('raw', 'sample_data', 'TXT_SAMPLE')\n",
    "TARGET_DIR = dir_manager.get_data_dir('preprocessed', 'sample_data', 'TXT_SAMPLE')\n",
    "\n",
    "# Create TARGET_DIR if not available\n",
    "if not os.path.isdir(TARGET_DIR):\n",
    "    os.makedirs(TARGET_DIR)\n",
    "\n",
    "f = [f for f in glob.glob(os.path.join(SOURCE_DIR, '*.txt'))]\n",
    "len(f), f[0].replace(SOURCE_DIR, TARGET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dask_get_adverbs(f):\n",
    "\n",
    "    worker = get_worker()\n",
    "\n",
    "    try:\n",
    "        nlp = worker.nlp\n",
    "    except AttributeError:\n",
    "        nlp = spacy.load('en_core_web_sm', disable=[\"ner\", \"parser\"])\n",
    "\n",
    "        # Fine to increase max_length since we're not using the NER and the parser.\n",
    "        nlp.max_length = int(1e9)\n",
    "        worker.nlp = nlp\n",
    "\n",
    "    with open(f, \"rb\") as fl:\n",
    "        text = fl.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    doc = nlp(text.lower())\n",
    "\n",
    "    return sorted({token.lemma_ for token in doc if token.pos_ == \"ADV\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dask_get_adverbs_from_files(flist):\n",
    "\n",
    "    worker = get_worker()\n",
    "\n",
    "    try:\n",
    "        nlp = worker.nlp\n",
    "    except AttributeError:\n",
    "        nlp = spacy.load('en_core_web_sm', disable=[\"ner\", \"parser\"])\n",
    "\n",
    "        # Fine to increase max_length since we're not using the NER and the parser.\n",
    "        nlp.max_length = int(1e9)\n",
    "        worker.nlp = nlp\n",
    "\n",
    "    def generate_text(flist):\n",
    "        for f in flist:\n",
    "            with open(f, \"rb\") as fl:\n",
    "                text = fl.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "            yield text.lower()  # texts.append(text.lower())\n",
    "\n",
    "    texts = generate_text(flist)\n",
    "\n",
    "    # texts = []\n",
    "    # for f in flist:\n",
    "    #     with open(f, \"rb\") as fl:\n",
    "    #         text = fl.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    #     texts.append(text.lower())\n",
    "\n",
    "    adverbs = set()\n",
    "\n",
    "    for doc in nlp.pipe(texts):\n",
    "        adverbs.update({token.lemma_ for token in doc if token.pos_ == \"ADV\"})\n",
    "\n",
    "    return adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=[\"ner\", \"parser\"])\n",
    "# Fine to increase max_length since we're not using the NER and the parser.\n",
    "nlp.max_length = int(1e9)\n",
    "\n",
    "\n",
    "def joblib_get_adverbs(f):\n",
    "\n",
    "    with open(f, \"rb\") as fl:\n",
    "        text = fl.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    doc = nlp(text.lower())\n",
    "\n",
    "    return sorted({token.lemma_ for token in doc if token.pos_ == \"ADV\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 301 ms, sys: 150 ms, total: 451 ms\nWall time: 1min 16s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2974"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with Parallel(n_jobs=4, backend='multiprocessing') as parallel:\n",
    "    res = parallel(delayed(joblib_get_adverbs)(i) for i in f)\n",
    "\n",
    "res = set([i for i in itertools.chain.from_iterable(res)])\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 8.3 s, sys: 4.85 s, total: 13.1 s\nWall time: 1min 41s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2974"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "b = db.from_sequence(f, npartitions=8)\n",
    "adverb_extractor = b.map(dask_get_adverbs)\n",
    "\n",
    "res = adverb_extractor.compute()\n",
    "\n",
    "res = set([i for i in itertools.chain.from_iterable(res)])\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 12.9 s, sys: 7 s, total: 19.9 s\nWall time: 2min 11s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2974"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "b = db.from_sequence(f, npartitions=8)\n",
    "adverb_extractor = b.map(dask_get_adverbs)\n",
    "\n",
    "res = adverb_extractor.compute()\n",
    "\n",
    "res = set([i for i in itertools.chain.from_iterable(res)])\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 10.4 s, sys: 5.26 s, total: 15.6 s\nWall time: 2min 9s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2974"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "%%time\n",
    "fi = iter(f)\n",
    "size = 5\n",
    "file_lists = [l for l in [list(itertools.islice(fi, size)) for i in range((len(f) // size) + 1)] if len(l) > 0]\n",
    "\n",
    "b = db.from_sequence(file_lists, npartitions=8)\n",
    "adverb_extractor = b.map(dask_get_adverbs_from_files)\n",
    "\n",
    "res = adverb_extractor.compute()\n",
    "\n",
    "res = set([i for i in itertools.chain.from_iterable(res)])\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 10.2 s, sys: 5.35 s, total: 15.5 s\nWall time: 1min 59s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2974"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "%%time\n",
    "fi = iter(f)\n",
    "size = 5\n",
    "file_lists = [l for l in [list(itertools.islice(fi, size)) for i in range((len(f) // size) + 1)] if len(l) > 0]\n",
    "\n",
    "b = db.from_sequence(file_lists, npartitions=8)\n",
    "adverb_extractor = b.map(dask_get_adverbs_from_files)\n",
    "\n",
    "res = adverb_extractor.compute()\n",
    "\n",
    "res = set([i for i in itertools.chain.from_iterable(res)])\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'\"l',\n '):',\n '-1974',\n '-the',\n '13that',\n '16-dec-2016',\n 'ably',\n 'about',\n 'above',\n 'abreast',\n 'abroad',\n 'absolutely',\n 'ac',\n 'accordingly',\n 'accurately',\n 'aco._ii],a',\n 'acquisitionhigher',\n 'across',\n 'actively',\n 'activitiest',\n 'actually',\n 'acutely',\n 'adc',\n 'additionally',\n 'adequately',\n 'admin-',\n 'administratively',\n 'admittedly',\n 'adverse',\n 'adversely',\n 'after',\n 'afterwards',\n 'again',\n 'aggressively',\n 'ago',\n 'ahclýil',\n 'ahead',\n 'aibandh',\n 'alike',\n 'all',\n 'almost',\n 'alone',\n 'along',\n 'alongside',\n 'already',\n 'alreety',\n 'also',\n 'alternatively',\n 'altogether',\n 'always',\n 'amendedand',\n 'amkodor',\n 'amply',\n 'anaconda',\n 'andaccesspath',\n 'andc',\n 'andneedspreviously',\n 'andstandard',\n 'andthereby',\n 'andwere',\n 'andwill',\n 'animously',\n 'anit',\n 'annually',\n 'antonio',\n 'anywhere',\n 'apart',\n 'apparently',\n 'apparertly',\n 'appreciably',\n 'approachdescribedpreviously',\n 'appropriately',\n 'approximately',\n 'arguably',\n 'around',\n 'artificially',\n 'as',\n 'aside',\n 'assessmentswere',\n 'assistancenecessarymainly',\n 'at',\n 'automatically',\n 'away',\n 'back',\n 'bankpositively',\n 'barely',\n 'basically',\n 'becauseofthe',\n 'before',\n 'behind',\n 'below',\n 'besides',\n 'best',\n 'better',\n 'biologically',\n 'briefly',\n 'broadly',\n 'by',\n 'cally',\n 'capably',\n 'carefully',\n 'careless',\n 'centrally',\n 'certainly',\n 'cheaply',\n 'chemically',\n 'chiefly',\n 'ciably',\n 'cifically',\n 'clearly',\n 'close',\n 'closely',\n 'coherently',\n 'collaboratively',\n 'collectively',\n 'commercially',\n 'commonly',\n 'comparatively',\n 'competitively',\n 'completely',\n 'compulsorily',\n 'conceptually',\n 'consequently',\n 'conservatively',\n 'considerably',\n 'consistently',\n 'constantly',\n 'continually',\n 'continuously',\n 'contrary',\n 'conveniently',\n 'conversely',\n 'correctly',\n 'correspondingly',\n 'counter',\n 'course',\n 'cp',\n 'creasingly',\n 'critically',\n 'crucially',\n 'crusher',\n 'cularly',\n 'culturally',\n 'cumulatively',\n 'currently',\n 'daily',\n 'date(s',\n 'dcc',\n 'dccs',\n 'de-',\n 'decisively',\n 'deep',\n 'definitely',\n 'dently',\n 'didnot',\n 'differently',\n 'diop',\n 'directly',\n 'disproportionately',\n 'distinctly',\n 'disulfide',\n 'ditionally',\n 'domestically',\n 'doubt',\n 'down',\n 'downstream',\n 'downward',\n 'dramatically',\n 'drastically',\n 'due',\n 'duly',\n 'duringthe',\n 'e.g.',\n 'early',\n 'eas',\n 'easier',\n 'easily',\n 'east',\n 'economically',\n 'effectively',\n 'efficiently',\n 'either',\n 'electrolytically',\n 'electronically',\n 'else',\n 'elsewhere',\n 'emdp',\n 'enough',\n 'ensuretimely',\n 'entirely',\n 'environmentally',\n 'equally',\n 'equitably',\n 'erally',\n 'ere',\n 'especially',\n 'essentially',\n 'even',\n 'evenly',\n 'eventually',\n 'ever',\n 'exactly',\n 'exceedingly',\n 'exceptionally',\n 'exclusively',\n 'expeditiously',\n 'explicitly',\n 'expressly',\n 'externally',\n 'extremely',\n 'f',\n 'fairly',\n 'fapad',\n 'far',\n 'fast',\n 'favin',\n 'favorably',\n 'fewer',\n 'finally',\n 'financially',\n 'fine',\n 'finely',\n 'first',\n 'fiscally',\n 'fittingly',\n 'flexibly',\n 'forestiere',\n 'formally',\n 'formerly',\n 'forth',\n 'fortunately',\n 'forward',\n 'free',\n 'freely',\n 'frequently',\n 'fully',\n 'fundamentally',\n 'further',\n 'furthermore',\n 'generally',\n 'geographically',\n 'ginally',\n 'globally',\n 'gradually',\n 'gratefully',\n 'greater',\n 'greatly',\n 'grissly',\n 'hard',\n 'hardly',\n 'hasbeenconsideredalikely',\n 'heavily',\n 'hence',\n 'here',\n 'hereafter',\n 'high',\n 'higher',\n 'highest',\n 'highly',\n 'hilly',\n 'historically',\n 'hlly',\n 'home',\n 'hot-',\n 'how',\n 'however',\n 'ideally',\n 'ifonly',\n 'ill',\n 'illegally',\n 'im-',\n 'immediately',\n 'implementedsmoothly',\n 'implicitly',\n 'importantly',\n 'improperly',\n 'in',\n 'in2005',\n 'inadvertently',\n 'incameroon',\n 'incase',\n 'inconakry',\n 'increasingly',\n 'indeed',\n 'independently',\n 'indicatively',\n 'indirectly',\n 'individually',\n 'indoualamaybe',\n \"ined'le\",\n 'inevitably',\n 'infrequently',\n 'inherently',\n 'initially',\n 'inland',\n 'inother',\n 'instead',\n 'intensively',\n 'inter',\n 'interchangeably',\n 'internally',\n 'internationally',\n 'inthe',\n 'intimately',\n 'intime',\n 'inutra',\n 'invariably',\n 'inward',\n 'ironically',\n 'irregularly',\n 'irrespective',\n 'is',\n 'jointly',\n 'just',\n 'kindly',\n 'landless',\n 'largely',\n 'larly',\n 'lastly',\n 'late',\n 'later',\n 'lawfully',\n 'lb',\n 'leach',\n 'least',\n 'legally',\n 'less',\n 'lesser',\n 'lightly',\n 'likely',\n 'likewise',\n 'little',\n 'locally',\n 'loicb',\n 'long',\n 'longer',\n 'low',\n 'lower',\n 'lowest',\n 'lytically',\n 'mainly',\n 'manually',\n 'manufac-',\n 'marginally',\n 'markedly',\n 'marketly',\n 'mately',\n 'may-',\n 'maybe',\n 'mcurrently',\n 'meantime',\n 'meanwhile',\n 'measureswill',\n 'mechanically',\n 'medically',\n 'merely',\n 'meticulously',\n 'mineralogically',\n 'mknelly',\n 'moderately',\n 'modestly',\n 'monthly',\n 'more',\n 'moreover',\n 'morethanlikely',\n 'most',\n 'mostly',\n 'much',\n 'mutually',\n 'nadvi',\n 'namely',\n 'nationally',\n 'nationwide',\n 'naturally',\n 'near',\n 'nearby',\n 'nearly',\n 'necessarily',\n 'necis',\n 'needspreviously',\n 'negatively',\n 'never',\n 'nevertheless',\n 'newly',\n 'next',\n 'ngo',\n 'no',\n 'nonetheless',\n 'normally',\n 'north',\n 'notably',\n 'notionally',\n 'now',\n 'nowadays',\n 'npmif',\n 'nsdi',\n 'o',\n 'obviously',\n 'od',\n 'odly',\n 'of',\n 'off',\n 'officially',\n 'offshore',\n 'often',\n 'on',\n 'once',\n 'online',\n 'only',\n 'onward',\n 'onwards',\n 'operationally',\n 'organizationally',\n 'originally',\n 'orthophoto',\n 'otherwise',\n 'out',\n 'out-',\n 'outside',\n 'outward',\n 'over',\n 'overall',\n 'overhead',\n 'overly',\n 'overnight',\n 'oversupply',\n 'painstakingly',\n 'parametrically',\n 'partially',\n 'particularly',\n 'partly',\n 'perfectly',\n 'perhaps',\n 'periodically',\n 'permanently',\n 'perversely',\n 'physically',\n 'piauí',\n 'pierrepozzo',\n 'politically',\n 'poorly',\n 'positively',\n 'possibly',\n 'potentially',\n 'power.47',\n 'practically',\n 'precariously',\n 'precisely',\n 'predominantly',\n 'preferably',\n 'preferentially',\n 'presently',\n 'presumably',\n 'previously',\n 'primarily',\n 'principally',\n 'prior',\n 'privately',\n 'probably',\n 'professionally',\n 'progressively',\n 'prominently',\n 'promptly',\n 'properly',\n 'proportionally',\n 'proportionately',\n 'publicly',\n 'quarterly',\n 'quickly',\n 'quite',\n 'rapidly',\n 'rapswere',\n 'rarely',\n 'rather',\n 're-',\n 'readily',\n 'realistically',\n 'really',\n 'reasonably',\n 'reatly',\n 'recently',\n 'regardless',\n 'regionally',\n 'regrettably',\n 'regularly',\n 'reinforces.103',\n 'relatively',\n 'remarkably',\n 'remotely',\n 'repeatedly',\n 'replac-',\n 'reportedly',\n 'representedonly',\n 'respectively',\n 'reviewedjointly',\n 'right',\n 'risingly',\n 'roughly',\n 'russiaalso',\n 'saadah',\n 'safely',\n 'satisfactorily',\n 'satisfactory',\n 'scebma',\n 'seasonally',\n 'second',\n 'sedere',\n 'seemingly',\n 'seldom',\n 'selectively',\n 'semi',\n 'separately',\n 'sequentially',\n 'sequently',\n 'seriously',\n 'severely',\n 'sexually',\n 'sharply',\n 'short',\n 'shortly',\n 'significantly',\n 'silvery',\n 'similarly',\n 'simply',\n 'simultaneously',\n 'since',\n 'sincerely',\n 'slightly',\n 'smoothly',\n 'so',\n 'socially',\n 'solely',\n 'some',\n 'somehow',\n 'sometimes',\n 'somewhat',\n 'somewhere',\n 'soon',\n 'south',\n 'sparsely',\n 'specifically',\n 'speedily',\n 'spondingly',\n 'springer',\n 'ssfully',\n 'starkly',\n 'statistically',\n 'staunchly',\n 'steadily',\n 'steeply',\n 'still',\n 'strategically',\n 'strictly',\n 'strongly',\n 'structurally',\n 'submittedquarterly',\n 'subsequently',\n 'substantially',\n 'substantively',\n 'successfully',\n 'successhlly',\n 'successtully',\n 'suddenly',\n 'sufficiently',\n 'suffiently',\n 'suitably',\n 'sure',\n 'surprisingly',\n 'sustainably',\n 'systematically',\n 'technically',\n 'technologically',\n 'temporally',\n 'temporarily',\n 'tentatively',\n 'that',\n 'then',\n 'theoretically',\n 'there',\n 'thereafter',\n 'thereby',\n 'therefore',\n 'therein',\n 'third',\n 'thirdly',\n 'thoroughly',\n 'though',\n 'threefold',\n 'through',\n 'thus',\n 'tially',\n 'tically',\n 'tightly',\n 'timely',\n 'tively',\n 'together',\n 'too',\n 'top',\n 'totally',\n 'traditionally',\n 'tutung',\n 'twice',\n 'typically',\n 'ultimately',\n 'unanimously',\n 'unconditionally',\n 'under',\n 'underground',\n 'underway',\n 'undoubtedly',\n 'unduly',\n 'unequivocally',\n 'unfavorably',\n 'unfortunately',\n 'uniformly',\n 'uniquely',\n 'uniter',\n 'unreliably',\n 'unsuccessfully',\n 'unsustainably',\n 'unusually',\n 'up',\n 'upstream',\n 'upward',\n 'upwards',\n 'urgently',\n 'us$0.6',\n 'us$53.3',\n 'us$7.0',\n 'usefully',\n 'usually',\n 'vastly',\n 'ventranasasan79',\n 'verbally',\n 'versa',\n 'vertically',\n 'very',\n 'vhlss',\n 'viously',\n 'virtually',\n 'voluntarily',\n 'well',\n 'west',\n 'when',\n 'whenever',\n 'where',\n 'whereby',\n 'wherein',\n 'wherever',\n 'whiteford',\n 'wholly',\n 'why',\n 'wide',\n 'widely',\n 'woefully',\n 'wor7d',\n 'worldwide',\n 'worryingly',\n 'worse',\n 'worst',\n 'xclusively',\n 'yearly',\n 'yet',\n '\\ufefffinally',\n '\\ufeffroughly',\n '\\ufeffultimately'}"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "set([i for i in itertools.chain.from_iterable(res)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_13720575.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_29697765.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_11620720.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_6719860.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_30662711.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_26181916.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_891710.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_740750.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_724956.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_8640074.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_12691447.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_11143237.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_12187862.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_724576.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_739916.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_12853118.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_18928240.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_440100.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_23927554.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_30243738.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_31118687.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_25141902.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_27179833.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_1557491.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_740391.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_20345939.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_26696289.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_734853.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_731917.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_12005593.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_16523320.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_30355908.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_12413058.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_27058244.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_15564465.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_13303073.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_29819652.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_735352.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_5673154.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_739182.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_725385.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_30732553.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_25863819.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_11330371.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_26498796.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_723866.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_3027821.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_11942928.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_17708351.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_7219311.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_14222627.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_25166113.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_727563.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_12160302.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_30906579.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_9064780.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_20352958.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_17966262.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_16870728.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_11807261.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_27408883.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_30689134.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_24791419.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_7170300.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_725428.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_5728165.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_26612026.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_1558643.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_6584995.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_9629351.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_5752096.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_9689786.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_732904.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_737854.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_741068.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_14758702.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_734839.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_14450867.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_26843165.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_729316.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_6343563.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_31245523.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_739071.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_726804.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_25377208.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_19761787.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_6622008.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_693271.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_726437.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_29752194.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_5764094.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_1553941.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_31345695.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_12576485.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_30633578.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_27677093.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_28084261.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_19456793.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_30711109.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_6552235.txt'],\n ['/workspace/data/raw/sample_data/TXT_SAMPLE/wb_697013.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_1560750.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_1346241.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_29722529.txt',\n  '/workspace/data/raw/sample_data/TXT_SAMPLE/wb_733203.txt']]"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}